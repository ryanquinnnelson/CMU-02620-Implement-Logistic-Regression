{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dental-blank",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "quality-employee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import exp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot  as plt\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ambient-recorder",
   "metadata": {},
   "source": [
    "# 1. K-nearest Neighbor Classifier\n",
    "### 1.1. Model Definition\n",
    "Non-parametric, no model, no learning.\n",
    "\n",
    "- Given $X_{new}$, find its k-nearest neighbors according to some distance measure\n",
    "    - Euclidean distance: $(X_i-X_{new})^T(X_i-X_{new})$\n",
    "- Classify $X_{new}$ as the majority vote, based on the labels of these neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rough-treasurer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "statewide-factory",
   "metadata": {},
   "source": [
    "# 2. Naïve Bayes Classifier\n",
    "### 2.1. Model Definition\n",
    "Model assumes all features are conditionally independent.\n",
    "\n",
    "$$P(Y|X_1,\\ldots,X_n)=\\frac{P(Y)\\prod_{i=1}^n P(X_i|Y)}{P(X_1,\\dots,X_n)}$$\n",
    "\n",
    "\n",
    "where \n",
    "- $X$ is a feature for a given sample. \n",
    "- $n$ is the total number of samples.\n",
    "- $Y$ is the label for a given sample.\n",
    "\n",
    "\n",
    "#### Subcomponents\n",
    "\n",
    "\n",
    "$P(Y)=\\pi^Y(1-\\pi)^{1-Y}$\n",
    "\n",
    "where \n",
    "- $\\pi$ is a parameter defining $P(Y=1)$ and must be learned.\n",
    "\n",
    "***\n",
    "If $X_i$ is discrete, $P(X_i|Y)$ follows a Multinoulli distribution:\n",
    "\n",
    "$P(X_i=k|Y=j)=\\prod_k \\theta_{ijk}^{(1-\\delta(X_i,k))}$\n",
    "\n",
    "where \n",
    "- $\\delta(X_i,k)$ is an indicator function which takes value 1 if $X_i=k$ and value 0 otherwise.\n",
    "- $k$: The number of possible values for a given feature.\n",
    "***\n",
    "\n",
    "\n",
    "\n",
    "If $X_i$ is continuous, $P(X_i|Y)$ follows a Gaussian distribution:\n",
    "\n",
    "$P(X_i|Y)\\sim N(\\mu_i,\\sigma_i^2)$\n",
    "\n",
    "where \n",
    "- $\\mu_i$ and $\\sigma_i^2$ are parameters which must be learned. \n",
    "***\n",
    "$P(X_1,\\dots,X_n)$\n",
    "\n",
    "where\n",
    "\n",
    "$P(X_1,\\dots,X_n)=P(Y=0)\\sum_{i=1}^n P(X_i|Y=0)+P(Y=1)\\sum_{i=1}^n P(X_i|Y=1)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "divine-johns",
   "metadata": {},
   "source": [
    "### 2.3. MLE for Naïve Bayes\n",
    "\n",
    "$$\\pi=\\frac{s_1}{n}$$\n",
    "\n",
    "where \n",
    "- $s_1$: number of samples with $Y=1$\n",
    "- $n$: total number of samples\n",
    "\n",
    "***\n",
    "\n",
    "$$\\theta_{ijk}=\\frac{s_{1,k}}{s_1}$$\n",
    "\n",
    "where\n",
    "- $s_{1,k}$: number of samples with $X_i=k,Y=1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "burning-convert",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given $X_{new}$:\n",
    "# - Compute $P(Y=1)\\prod_{i=1}^nP(X_j=X_{j_{new}}|Y=1)$\n",
    "# - Compute $P(Y=0)\\prod_{i=1}^nP(X_j=X_{j_{new}}|Y=0)$\n",
    "# - Classify $X_{new}$ as the label with the higher probability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "answering-accessory",
   "metadata": {},
   "source": [
    "### 2.4. MAP estimation for Naïve Bayes\n",
    "\n",
    "$$\\pi=\\frac{s_1+\\alpha_0}{n+\\alpha_0 + \\beta_0}$$\n",
    "\n",
    "where \n",
    "- $s_1$: number of samples with $Y=1$\n",
    "- $n$: total number of samples\n",
    "- $\\alpha_0$:\n",
    "- $\\beta_0$:\n",
    "\n",
    "***\n",
    "\n",
    "$$\\theta_{ijk}=\\frac{s_{1,k}+\\alpha_{ijk0}}{s_1+\\alpha_{ijk0}+\\beta_{ijk0}}$$\n",
    "\n",
    "where\n",
    "- $s_{1,k}$: number of samples with $X_i=k,Y=1$\n",
    "- $\\alpha_{ijk0}$:\n",
    "- $\\beta_{ijk0}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threaded-amino",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "tropical-sullivan",
   "metadata": {},
   "source": [
    "# 3. Logistic Regression\n",
    "### 3.1. Model Definition (two class)\n",
    "Transforms continuous value from linear regression into discrete values for output.\n",
    "\n",
    "$$P(Y=1|X=\\{X_1,\\ldots, X_n\\})=\\frac{1}{1+\\exp{(w_0 + \\sum_{i=1}^n w_iX_i)}}$$\n",
    "\n",
    "$$P(Y=0|X=\\{X_1,\\ldots, X_n\\})=\\frac{\\exp{(w_0 + \\sum_{i=1}^n w_iX_i)}}{1+\\exp{(w_0 + \\sum_{i=1}^n w_iX_i)}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "working-acrobat",
   "metadata": {},
   "source": [
    "### 3.2. MCLE for Logistic Regression (two class)\n",
    "We want to use MCLE to learn the model parameters. MCLE cannot be solved in closed-form with respect to $W$.\n",
    "\n",
    "$$\\hat{W}_{MCLE}=\\underset{W}{argmax} \\prod_l P(Y^l|X^l,W)$$\n",
    "\n",
    "where\n",
    "- $l$: number of training examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defined-coffee",
   "metadata": {},
   "source": [
    "### 3.3. MCLE  for Logistic Regression (two class) with Gradient Descent\n",
    "Parameters can be derived using gradient descent because logistic regression is concave. Start with a random initialization of parameters. Repeat until the change is less than $\\epsilon$, that is, until $l(W)_t - l(W)_{t-1} < \\epsilon$.\n",
    "\n",
    "$$l(W)=\\sum_l Y^l(w_0+\\sum_i^n w_i X^l_i)-ln(1+exp(w_0+\\sum_i^n w_i X^l_i))$$\n",
    "\n",
    "$$w_i \\leftarrow w_i + \\eta \\nabla(W) $$\n",
    "\n",
    "where \n",
    "- $\\eta$ is step size (learning rate)\n",
    "- $X_i^l$: value of $X_i$ for the $l$th training example.\n",
    "- $\\nabla(W)$ is the gradient\n",
    "\n",
    "***\n",
    "\n",
    "#### Subcomponents\n",
    "\n",
    "$\\nabla(W)=\\frac{\\partial l(W)}{\\partial w_i}=\\sum_l X^l_i\\left(Y^l-\\hat{P}(Y^l=1|X^l,W)\\right)$\n",
    "\n",
    "where\n",
    "- $Y^l-\\hat{P}(Y^l=1|X^l,W)$ is the prediction error\n",
    "- $\\hat{P}(Y^l=1|X^l,W)=\\frac{exp(w_0+\\sum_iw_iX_i)}{1+exp(w_0+\\sum_iw_iX_i)}$\n",
    "\n",
    "\n",
    "According to Mitchell, we accommodate weight $w_0$ by assuming an imaginary $X_0=1$ for all $l$.\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposed-surgeon",
   "metadata": {},
   "source": [
    "Pattern for gradient:\n",
    "\n",
    "$$\\frac{\\partial l(W)}{\\partial w_0}=\\sum_l 1 (Y^l - P(Y^l=1|X^l,W))$$\n",
    "\n",
    "$$\\frac{\\partial l(W)}{\\partial w_1}=\\sum_l X_1^l (Y^l - P(Y^l=1|X^l,W))$$\n",
    "\n",
    "$$\\vdots$$\n",
    "\n",
    "$$\\frac{\\partial l(W)}{\\partial w_n}=\\sum_l X_n^l (Y^l - P(Y^l=1|X^l,W))$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "durable-veteran",
   "metadata": {},
   "outputs": [],
   "source": [
    "#?? need to mean center data?\n",
    "#?? when to add imaginary 1 row?\n",
    "#?? how to accommodate w_0? Assume extra x row of all 1's? best way?\n",
    "#?? log likelihood returns vector. how to compare vector difference vs epsilon?\n",
    "#?? how to set starting weights?\n",
    "#?? how to choose epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "literary-houston",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X,y_true,eta,epsilon,W):\n",
    "    '''\n",
    "    Performs gradient descent to derive regression coefficients.\n",
    "    '''\n",
    "    # set weights\n",
    "    weights = W\n",
    "    \n",
    "    \n",
    "    # append imaginary column X_0=1 to accommodate w_0\n",
    "    X_aug = add_X0(X) \n",
    "    print(X_aug)\n",
    "    \n",
    "    # calculate original log likelihood\n",
    "    prev_log_likelihood = calc_log_likelihood(X_aug,y_true,weights)\n",
    "    print('prev',prev_log_likelihood)\n",
    "    \n",
    "#     # perform gradient descent\n",
    "#     count = 0\n",
    "#     diff = np.Inf\n",
    "#     while diff > epsilon:\n",
    "    \n",
    "#         count += 1\n",
    "#         if count > 100000:\n",
    "#             break  # stop descending\n",
    "        \n",
    "#         # update weights\n",
    "#         y_pred = get_y_predictions(X_aug,weights)\n",
    "#         gradient = calc_gradient(X_aug,y_true,y_pred)\n",
    "#         weights = update_weights(weights,eta,gradient)\n",
    "\n",
    "#         # calculate difference\n",
    "#         log_likelihood = calc_log_likelihood(X_aug,y_true,weights)\n",
    "#         diff = prev_log_likelihood - log_likelihood\n",
    "# #         print(diff)\n",
    "#         diff = np.min(diff)  #??\n",
    "# #         print(diff)\n",
    "        \n",
    "#         # save log likelihood for next round\n",
    "#         prev_log_likelihood = log_likelihood\n",
    "        \n",
    "#     print('count of rounds',count)\n",
    "#     return weights   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "measured-caution",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test add_X0()\n",
      "test add_X0()\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "noble-indianapolis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test calc_log_likelihood()\n",
      "ones [1. 1. 1.]\n",
      "XW [3.3 1.7 3.4]\n",
      "inner [4.3 2.7 4.4]\n"
     ]
    }
   ],
   "source": [
    "def calc_log_likelihood(X,y_true,W):\n",
    "    '''\n",
    "    Calculates log likelihood.\n",
    "    '''\n",
    "    \n",
    "    # left half\n",
    "    XW = np.matmul(X,W)\n",
    "    YXW = y_true + XW  # all L samples can be summed in parallel \n",
    "\n",
    "    # right half\n",
    "    num_rows = X.shape[0]\n",
    "    ones = np.ones(num_rows)  # create a vector of 1's\n",
    "    inner = ones + np.exp(XW)\n",
    "    ln_XW = np.log(inner)\n",
    "    print('ones',ones)\n",
    "    print('XW',XW)\n",
    "    print('inner',inner)\n",
    "    \n",
    "    return YXW - ln_XW\n",
    "\n",
    "print('test calc_log_likelihood()')\n",
    "X_test = np.array([[ .1, .5, .1 ,.1], \n",
    "              [ .1, .1, .1 ,.1], \n",
    "              [ .1, .1, .2 ,.3]])\n",
    "W_test = np.array([2,4,5,6])\n",
    "y_true_test = np.array([1,0,0])\n",
    "num_rows = X.shape[0]\n",
    "ones = np.ones(num_rows)\n",
    "\n",
    "expect_YXW = np.array([4.3, 1.7, 3.4])\n",
    "\n",
    "expect_inner = \n",
    "expected = expect_YXW - np.log(expect_inner)\n",
    "actual = calc_log_likelihood(X_test,y_true_test,W_test)\n",
    "np.testing.assert_allclose(actual,expected)  # rounding makes exact match impossible\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "pediatric-infrared",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test get_y_prediction()\n"
     ]
    }
   ],
   "source": [
    "def get_y_prediction(X,W):\n",
    "    '''\n",
    "    Gets y predictions for one X_i.\n",
    "    Assumes \"imaginary\" X_0 = 1 for all samples has been added to the matrix.\n",
    "    '''\n",
    "\n",
    "    a = np.dot(X,W)\n",
    "    b = exp(a)\n",
    "    c = 1 + exp(a)\n",
    "\n",
    "    return b/c\n",
    "\n",
    "print('test get_y_prediction()')\n",
    "X = np.array([1,1,2])\n",
    "W = np.array([4,5,6])\n",
    "expected = 1318815734 / 1318815735\n",
    "actual = get_y_prediction(X,W)\n",
    "assert actual == expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "turned-teacher",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test get_y_predictions()\n"
     ]
    }
   ],
   "source": [
    "def get_y_predictions(X,W):\n",
    "    '''\n",
    "    Gets y predictions for all samples.\n",
    "    Assumes \"imaginary\" X_0 = 1 for all samples has been added to the matrix.\n",
    "    '''\n",
    "    num_rows = X.shape[0]\n",
    "    XW = np.matmul(X,W)  # all L samples can be summed in parallel\n",
    "    top = np.exp(XW)\n",
    "    ones = np.ones(num_rows)  # create a vector of 1's\n",
    "    bottom = ones + top\n",
    "    return top / bottom\n",
    "        \n",
    "    \n",
    "print('test get_y_predictions()')\n",
    "X = np.array([[ .1, .5, .1 ,.1], \n",
    "              [ .1, .1, .1 ,.1], \n",
    "              [ .1, .1, .2 ,.3]])\n",
    "W = np.array([2,4,5,6])\n",
    "\n",
    "a = get_y_prediction(X[0],W)\n",
    "b = get_y_prediction(X[1],W)\n",
    "c = get_y_prediction(X[2],W)\n",
    "\n",
    "expected = [a,b,c]\n",
    "actual = get_y_predictions(X,W).tolist()\n",
    "assert actual==expected,actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "exterior-hours",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test calc_gradient()\n"
     ]
    }
   ],
   "source": [
    "def calc_gradient(X,y_true,y_pred):\n",
    "    '''\n",
    "    Calculates the gradient.\n",
    "    Assumes \"imaginary\" X_0 = 1 for all samples has been added to the matrix.\n",
    "    \n",
    "    Args:\n",
    "        X: L x n matrix, where L is the number of samples and n is the number of features\n",
    "        y_true: L x 1 vector\n",
    "        y_pred: L x 1 vector\n",
    "        \n",
    "    Return:\n",
    "        Gradient in the form of an L x 1 vector\n",
    "    '''\n",
    "    y_err = y_true - y_pred\n",
    "    return np.matmul(X.T,y_err)\n",
    "\n",
    "'''\n",
    "Explanation of how the function works.\n",
    "\n",
    "X                y_err\n",
    "| 5 | 1 | 1 |    | 0 |\n",
    "| 1 | 1 | 1 |    |-1 |\n",
    "| 1 | 2 | 3 |    | 1 |\n",
    "\n",
    "Calculating the partial for the ith feature is the same as taking the dot product of the ith column of X and y_err.\n",
    "\n",
    "X_1         y_err\n",
    "|x11|       | y1 | \n",
    "|x21|  dot  | y2 | \n",
    "|x31|       | y3 |\n",
    "\n",
    "w_1 = (x11*y1) + (x21*y2) + (x31*y3)\n",
    "\n",
    "X_2         y_err\n",
    "|x12|       | y1 | \n",
    "|x22|  dot  | y2 | \n",
    "|x32|       | y3 |\n",
    "\n",
    "w_2 = (x12*y1) + (x22*y2) + (x32*y3)\n",
    "\n",
    "X_3         y_err\n",
    "|x13|       | y1 | \n",
    "|x23|  dot  | y2 | \n",
    "|x33|       | y3 |\n",
    "\n",
    "w_3 = (x13*y1) + (x23*y2) + (x33*y3)\n",
    "\n",
    "Instead of calculating partials one by one, we can perform matrix multiplication to do all at the same time. \n",
    "However, we need to transpose X first, because we want to perform column-wise multiplications.\n",
    "\n",
    "X              y_err\n",
    "|x11|x12|x13|  | y1 | \n",
    "|x21|x22|x23|  | y2 |\n",
    "|x31|x32|x33|  | y3 |\n",
    "\n",
    "(X)(y_err)\n",
    "| (x11*y1) + (x12*y2) + (x13*y3) |\n",
    "| (x21*y1) + (x22*y2) + (x23*y3) |\n",
    "| (x31*y1) + (x32*y2) + (x33*y3) |\n",
    "\n",
    "X_transpose    y_err\n",
    "|x11|x21|x31|  | y1 | \n",
    "|x12|x22|x32|  | y2 |\n",
    "|x13|x23|x33|  | y3 |\n",
    "\n",
    "W = (X_transpose)(y_err)\n",
    "| w1 |    | (x11*y1) + (x21*y2) + (x31*y3) |\n",
    "| w2 | =  | (x12*y1) + (x22*y2) + (x32*y3) |\n",
    "| w3 |    | (x13*y1) + (x23*y2) + (x33*y3) |\n",
    "'''\n",
    "\n",
    "print('test calc_gradient()')\n",
    "X = np.array([[ 1, 5, 1 ,1], \n",
    "              [ 1, 1, 1 ,1], \n",
    "              [ 1, 1, 2 ,3]])  # includes imaginary X_0=1 column\n",
    "y_true = np.array([1, 0, 1])\n",
    "y_pred = np.array([1, 1, 0])\n",
    "expected = np.array([0, 0, 1, 2]).tolist()\n",
    "actual = calc_gradient(X,y_true,y_pred).tolist()\n",
    "assert actual == expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "finnish-placement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test update_weights()\n"
     ]
    }
   ],
   "source": [
    "def update_weights(W,eta,gradient):\n",
    "    '''\n",
    "    W <- W + eta * gradient\n",
    "    '''\n",
    "    change = eta * gradient\n",
    "    return W + change\n",
    "\n",
    "print('test update_weights()')\n",
    "eta = 0.01\n",
    "gradient = np.array([1,-2,3])\n",
    "W = np.array([4,5,6])\n",
    "expected = [4.01,4.98,6.03]\n",
    "actual = update_weights(W,eta,gradient).tolist()\n",
    "assert actual == expected,actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "atomic-detection",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "partial-detector",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.26027422  1.28265276]\n",
      " [-0.93884188 -0.96598454]\n",
      " [-0.3875902   0.99848772]\n",
      " [ 0.2593788  -0.88002654]\n",
      " [-0.42430349 -0.36606471]]\n",
      "[1 0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "X1, y1 = make_classification(n_features=2, n_redundant=0, n_informative=1,\n",
    "                             n_clusters_per_class=1)\n",
    "plt.scatter(X1[:, 0], X1[:, 1], marker='o', c=y1,\n",
    "            s=25, edgecolor='k')\n",
    "plt.show()\n",
    "print(X1[:5])\n",
    "print(y1[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "still-alcohol",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.02237854 -0.90482642  2.61089752  0.37935226  0.2096318 ]\n"
     ]
    }
   ],
   "source": [
    "X1 = np.array([[-1.26027422,  1.28265276],\n",
    "                 [-0.93884188, -0.96598454],\n",
    "                 [-0.3875902,   0.99848772],\n",
    "                 [ 0.2593788,  -0.88002654],\n",
    "                 [-0.42430349, -0.36606471]])\n",
    "y1 = np.array([1, 0, 1, 0, 0])\n",
    "\n",
    "X1_aug = np.array([[ 1.,         -1.26027422,  1.28265276],\n",
    "                     [ 1. ,        -0.93884188, -0.96598454],\n",
    "                     [ 1.    ,     -0.3875902,   0.99848772],\n",
    "                     [ 1.   ,       0.2593788,  -0.88002654],\n",
    "                     [ 1.   ,      -0.42430349, -0.36606471]])\n",
    "W = np.ones(3)\n",
    "\n",
    "a = np.matmul(X1_aug,W)\n",
    "b = y1 + a\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "distant-shooting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.         -1.26027422  1.28265276]\n",
      " [ 1.         -0.93884188 -0.96598454]\n",
      " [ 1.         -0.3875902   0.99848772]\n",
      " [ 1.          0.2593788  -0.88002654]\n",
      " [ 1.         -0.42430349 -0.36606471]]\n",
      "ones [1. 1. 1. 1. 1.]\n",
      "XW [ 1.02237854 -0.90482642  1.61089752  0.37935226  0.2096318 ]\n",
      "inner [2.02237854 0.09517358 2.61089752 1.37935226 1.2096318 ]\n",
      "prev [1.31810423 1.44722648 1.65120348 0.05773825 0.01931578]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.LogisticRegression at 0x7f83a61c2748>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(eta=0.01,epsilon=0.001)\n",
    "lr.fit(X1,y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "raising-london",
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph line across data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "congressional-retirement",
   "metadata": {},
   "source": [
    "### 3.4. MAP estimation  for Logistic Regression (two class) with Gradient Descent\n",
    "Regularization term helps reduce overfitting, especially when training data is sparse.\n",
    "\n",
    "$$l(W)=?$$\n",
    "\n",
    "$$w_i \\leftarrow w_i -\\eta\\lambda w_i + \\eta \\sum_l X^l_i\\left(Y^l-\\hat{P}(Y^l=1|X^l,W)\\right) $$\n",
    "\n",
    "where\n",
    "- $\\lambda$ is a regularization term, $\\lambda=\\frac{1}{2\\sigma^2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contemporary-stress",
   "metadata": {},
   "source": [
    "### 3.5. Model Definition (multiclass)\n",
    "Logistic Regression for more than two classes. Learn $R-1$ set of weights.\n",
    "\n",
    "For $k<R$:\n",
    "\n",
    "$$P(Y=y_k|X=\\{X_1,\\ldots, X_n\\})=\\frac{\\exp{(w_{k,0} + \\sum_{i=1}^n w_{k,i}X_i)}}{1+\\sum_{j=1}^{R-1}\\exp{(w_{j,0} + \\sum_{i=1}^n w_{ji}X_i)}}$$\n",
    "\n",
    "where\n",
    "- $R$: number of classes\n",
    "\n",
    "***\n",
    "\n",
    "For $k=R$:\n",
    "\n",
    "$$P(Y=y_R|X=\\{X_1,\\ldots, X_n\\})=\\frac{1}{1+\\sum_{j=1}^{R-1}\\exp{(w_{j,0} + \\sum_{i=1}^n w_{ji}X_i)}}$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
